
@inproceedings{yao2021wenet,
  title     = {WeNet: Production Oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit},
  author    = {Yao, Zhuoyuan and Wu, Di and Wang, Xiong and Zhang, Binbin and Yu, Fan and Yang, Chao and Peng, Zhendong and Chen, Xiaoyu and Xie, Lei and Lei, Xin},
  booktitle = {Proc. Interspeech},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.01547}
}

@inproceedings{pratap2020scaling,
  title     = {Scaling Up Online Speech Recognition Using ConvNets},
  author    = {Pratap, Vineel and Xu, Qiantong and Sriram, Anuroop and Synnaeve, Gabriel and Kahn, Jacob and others},
  booktitle = {Proc. Interspeech},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.03031}
}

@inproceedings{radford2023whisper,
  title     = {Robust Speech Recognition via Large-Scale Weak Supervision},
  author    = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle = {Proc. ICML},
  year      = {2023},
  url       = {https://arxiv.org/abs/2212.04356}
}

@inproceedings{baevski2020wav2vec2,
  title     = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
  author    = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.11477}
}

@inproceedings{ardila2020commonvoice,
  title     = {Common Voice: A Massively-Multilingual Speech Corpus},
  author    = {Ardila, Rosana and Branson, Megan and Davis, Kelly and others},
  booktitle = {Proc. LREC},
  year      = {2020},
  url       = {https://aclanthology.org/2020.lrec-1.520/}
}

@article{le2024phowhisper,
  title   = {PhoWhisper: Automatic Speech Recognition for Vietnamese},
  author  = {Le, The and others},
  journal = {arXiv preprint},
  year    = {2024},
  url     = {https://arxiv.org/abs/2406.02555}
}

@article{lee2024speechmassive,
  title   = {Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond},
  author  = {Lee, Byungkeun and others},
  journal = {arXiv preprint},
  year    = {2024},
  url     = {https://arxiv.org/abs/2408.03900}
}

@article{vlsp2020asr,
  title   = {ASR Challenge: Vietnamese Automatic Speech Recognition (VLSP 2020-ASR)},
  author  = {Nguyen, Ha Thanh Mai and others},
  journal = {Journal of Computer Science and Cybernetics},
  year    = {2022}
}

@misc{vivos2016,
  title     = {VIVOS: Vietnamese Speech Corpus for Automatic Speech Recognition},
  author    = {{AILAB, VNUHCM-US}},
  year      = {2016},
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.7068130},
  url       = {https://zenodo.org/records/7068130}
}

@article{zhang2020benchmarking,
  title   = {Benchmarking LF-MMI, CTC and RNN-T Criteria for Streaming ASR},
  author  = {Zhang, Xian and others},
  journal = {arXiv preprint},
  year    = {2020},
  url     = {https://arxiv.org/abs/2011.04785}
}

@article{srivastav2025openasr,
  title   = {Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation},
  author  = {Srivastav, Vaibhav and others},
  journal = {arXiv preprint},
  year    = {2025},
  url     = {https://arxiv.org/abs/2510.06961}
}

@inproceedings{zhuo2025vietasr,
  title     = {VietASR: Achieving Industry-level Vietnamese ASR with 50-hour Labeled Data and Large-Scale Speech Pretraining},
  author    = {Zhuo, Jianheng and Yang, Yifan and Shao, Yiwen and Xu, Yong and Yu, Dong and Yu, Kai and Chen, Xie},
  booktitle = {Proc. Interspeech 2025},
  year      = {2025},
  pages     = {1163--1167},
  doi       = {10.21437/Interspeech.2025-398},
  url       = {https://www.isca-archive.org/interspeech_2025/zhuo25_interspeech.html}
}

@article{hai2022vlsp2021asr,
  title   = {ASR Challenge: Vietnamese Automatic Speech Recognition},
  author  = {Hai, Do Van and Viet, Nguyen Van and Anh, Nguyen Ngoc and others},
  journal = {VNU Journal of Science: Computer Science and Communication Engineering},
  year    = {2022},
  volume  = {38},
  number  = {1},
  pages   = {1--9},
  doi     = {10.25073/2588-1086/vnucsce.356},
  url     = {https://js.vnu.edu.vn/CSC/article/view/356}
}

@inproceedings{dinh2024vimd,
  title     = {Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges},
  author    = {Dinh, Nguyen Van and Dang, Thanh Chi and Nguyen, Luan Thanh and Nguyen, Kiet Van},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2024},
  pages     = {7476--7498},
  url       = {https://aclanthology.org/2024.emnlp-main.426/}
}

@article{benzeghiba2007variability,
  title   = {Automatic Speech Recognition and Speech Variability: A Review},
  author  = {Benzeghiba, M. and De Mori, R. and Deroo, O. and Dupont, S. and Erbes, T. and Jouvet, D. and Fissore, L. and Laface, P. and Mertins, A. and Ris, C. and Rose, R. and Tyagi, V. and Wellekens, C.},
  journal = {Speech Communication},
  year    = {2007},
  volume  = {49},
  number  = {10--11},
  pages   = {763--786},
  doi     = {10.1016/j.specom.2007.02.006},
  url     = {https://doi.org/10.1016/j.specom.2007.02.006}
}
@article{barker2017chime3,
  title   = {The third {CHiME} Speech Separation and Recognition Challenge: Analysis and Outcomes},
  author  = {Barker, Jon and Marxer, Ricard and Vincent, Emmanuel and Watanabe, Shinji},
  journal = {Computer Speech \& Language},
  year    = {2017},
  volume  = {46},
  pages   = {605--626},
  doi     = {10.1016/j.csl.2016.10.005},
  url     = {https://doi.org/10.1016/j.csl.2016.10.005}
}

@inproceedings{ko2015audioaugmentation,
  title     = {Audio Augmentation for Speech Recognition},
  author    = {Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle = {Proc. Interspeech 2015},
  year      = {2015},
  pages     = {3586--3590},
  doi       = {10.21437/Interspeech.2015-711},
  url       = {https://www.isca-archive.org/interspeech_2015/ko15_interspeech.html}
}
  
@misc{linhtran92_vietyoutubeasr_v2,
  title        = {viet\_youtube\_asr\_corpus\_v2 (dataset)},
  author       = {linhtran92},
  year         = {2024},
  howpublished = {Hugging Face Datasets},
  note         = {Accessed 2026-02-26},
  url          = {https://huggingface.co/datasets/linhtran92/viet_youtube_asr_corpus_v2}
}

@inproceedings{bisani2004bootstrap,
  title     = {Bootstrap Estimates for Confidence Intervals in {ASR} Performance Evaluation},
  author    = {Bisani, Maximilian and Ney, Hermann},
  booktitle = {Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2004},
  volume    = {1},
  pages     = {409--412},
  doi       = {10.1109/ICASSP.2004.1326009},
  url       = {https://doi.org/10.1109/ICASSP.2004.1326009}
}

@inproceedings{liu2020blockwisebootstrap,
  title     = {Statistical Testing on {ASR} Performance via Blockwise Bootstrap},
  author    = {Liu, Zhe and Peng, Fuchun},
  booktitle = {Proc. Interspeech 2020},
  year      = {2020},
  pages     = {596--600},
  doi       = {10.21437/Interspeech.2020-1338},
  url       = {https://www.isca-archive.org/interspeech_2020/liu20c_interspeech.html}
}

@article{sproat2001nsw,
  title   = {Normalization of Non-standard Words},
  author  = {Sproat, Richard and Black, Alan W. and Chen, Stanley and Kumar, Shankar and Ostendorf, Mari and Richards, Christopher},
  journal = {Computer Speech \& Language},
  year    = {2001},
  volume  = {15},
  number  = {3},
  pages   = {287--333},
  doi     = {10.1006/csla.2001.0169},
  url     = {https://doi.org/10.1006/csla.2001.0169}
}

@article{zhang2019textnorm,
  title   = {Neural Models of Text Normalization for Speech Applications},
  author  = {Zhang, Hao and Sproat, Richard and Ng, Axel H. and Stahlberg, Felix and Peng, Xiaochang and Gorman, Kyle and Roark, Brian},
  journal = {Computational Linguistics},
  year    = {2019},
  volume  = {45},
  number  = {2},
  pages   = {293--337},
  doi     = {10.1162/COLI_a_00349},
  url     = {https://doi.org/10.1162/COLI_a_00349}
}

@misc{nguyen2019punctuation,
  title        = {Fast and Accurate Capitalization and Punctuation for Automatic Speech Recognition Using Transformer and Chunk Merging},
  author       = {Nguyen, Binh and Nguyen, Vu Bao Hung and Nguyen, Hien and Phuong, Pham Ngoc and Nguyen, The-Loc and Do, Quoc Truong and Mai, Luong Chi},
  year         = {2019},
  howpublished = {arXiv},
  doi          = {10.48550/arXiv.1908.02404},
  url          = {https://arxiv.org/abs/1908.02404}
}

@inproceedings{liang2023codeswitchner,
  title     = {Improving Code-Switching and Name Entity Recognition in {ASR} with Speech Editing based Data Augmentation},
  author    = {Liang, Zheng and Song, Zheshu and Ma, Ziyang and Du, Chenpeng and Yu, Kai and Chen, Xie},
  booktitle = {Proc. Interspeech 2023},
  year      = {2023},
  pages     = {919--923},
  doi       = {10.21437/Interspeech.2023-923},
  url       = {https://www.isca-archive.org/interspeech_2023/liang23b_interspeech.html}
}

@inproceedings{selfridge2011stability,
  title={Stability and accuracy in incremental speech recognition},
  author={Selfridge, Ethan and Arizmendi, Iker and Heeman, Peter},
  booktitle={Proc. SIGDIAL},
  year={2011}
}

@inproceedings{ma2020emformer,
  title={Emformer: Efficient memory transformer for streaming ASR},
  author={Ma, Yiming and others},
  booktitle={Proc. Interspeech},
  year={2020}
}
